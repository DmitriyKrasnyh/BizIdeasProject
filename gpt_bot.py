import os
from aiogram import Bot, Dispatcher, types
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.utils import executor
from supabase import create_client
from dotenv import load_dotenv
import openai
from datetime import datetime

load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
bot = Bot(token=os.getenv("TELEGRAM_BOT_TOKEN"))
dp = Dispatcher(bot)
openai.api_key = os.getenv("OPENAI_API_KEY")

supabase = create_client(os.getenv("VITE_SUPABASE_URL"), os.getenv("VITE_SUPABASE_ANON_KEY"))

# /start
@dp.message_handler(commands=['start'])
async def start(msg: types.Message):
    await msg.reply("üëã –ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏ –Ω–µ–º–Ω–æ–≥–æ –æ —Å–≤–æ—ë–º –±–∏–∑–Ω–µ—Å–µ, –∏ —è –ø–æ–¥—Å–∫–∞–∂—É, –∫–∞–∫ –µ–≥–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã.")

# /help
@dp.message_handler(commands=['help'])
async def help_command(msg: types.Message):
    await msg.reply("‚ÑπÔ∏è –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–≤–æ–µ–≥–æ –±–∏–∑–Ω–µ—Å–∞ ‚Äî —è –ø–æ–¥—Å–∫–∞–∂—É, –∫–∞–∫ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—É—é –∏–¥–µ—é. –ï—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å —Å–º–µ–Ω–∏—Ç—å –∏–¥–µ—é, –Ω–∞–∂–º–∏ '–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –∏–¥–µ—é'.")

# –û—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
@dp.message_handler()
async def handle_biz_question(msg: types.Message):
    username = f"@{msg.from_user.username}"

    # –ù–∞–π–¥—ë–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ telegram
    user_response = supabase.table("users").select("*").eq("telegram", username).single().execute()

    if not user_response.data:
        await msg.reply("‚ùå –¢—ã –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω. –£–∫–∞–∂–∏ —Å–≤–æ–π Telegram –≤ –ø—Ä–æ—Ñ–∏–ª–µ –Ω–∞ —Å–∞–π—Ç–µ.")
        return

    user = user_response.data
    user_id = user["user_id"]

    # –ù–∞–π–¥—ë–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –∏–¥–µ—é
    idea_response = supabase.table("userideas").select("idea_id").eq("user_id", user_id).single().execute()
    if not idea_response.data:
        await msg.reply("‚ùó –¢—ã –ø–æ–∫–∞ –Ω–µ –≤—ã–±—Ä–∞–ª –±–∏–∑–Ω–µ—Å-–∏–¥–µ—é –Ω–∞ —Å–∞–π—Ç–µ.")
        return

    idea_id = idea_response.data["idea_id"]
    idea_info = supabase.table("trendingideas").select("title, description").eq("idea_id", idea_id).single().execute().data

    # GPT-–∑–∞–ø—Ä–æ—Å
    gpt_prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç–∞—Ä—Ç–∞–ø–∞–º. –£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –±–∏–∑–Ω–µ—Å: "{msg.text}".
–í–æ—Ç –∏–¥–µ—è, –∫–æ—Ç–æ—Ä—É—é –æ–Ω –≤—ã–±—Ä–∞–ª: "{idea_info['title']} ‚Äî {idea_info['description']}".

–ü–æ–¥—Å–∫–∞–∂–∏, –∫–∞–∫ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ –±–∏–∑–Ω–µ—Å –ø–æ–¥ —ç—Ç—É –∏–¥–µ—é.
–û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∫—Ä–∞—Ç–∫–æ, –ø–æ–ª–µ–∑–Ω–æ –∏ –ø–æ –¥–µ–ª—É.
"""

    try:
        gpt_reply = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": gpt_prompt}],
            temperature=0.7,
        )
        answer = gpt_reply.choices[0].message.content.strip()

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è
        supabase.table("userhistory").insert({
            "user_id": user_id,
            "action_type": "gpt_recommendation",
            "action_time": datetime.utcnow().isoformat(),
            "details": f"input: {msg.text}"
        }).execute()

        # –û—Ç–≤–µ—Ç —Å –∫–Ω–æ–ø–∫–æ–π
        kb = InlineKeyboardMarkup().add(
            InlineKeyboardButton("üîÑ –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –∏–¥–µ—é", callback_data="try_other")
        )
        await msg.reply(answer, reply_markup=kb)

    except Exception as e:
        await msg.reply(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–∫–∏ "–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –∏–¥–µ—é"
@dp.callback_query_handler(lambda c: c.data == "try_other")
async def handle_other_idea(callback: types.CallbackQuery):
    await callback.message.answer("üîÅ –•–æ—Ä–æ—à–æ! –ó–∞–π–¥–∏ –Ω–∞ —Å–∞–π—Ç –∏ –≤—ã–±–µ—Ä–∏ –¥—Ä—É–≥—É—é –∏–¥–µ—é ‚Äî —è –ø–æ–¥—Å—Ç—Ä–æ—é—Å—å.")
    await callback.answer()

# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)
